{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Aztec Summary Report\n",
    "## Initial Investigation of Censorship Impact\n",
    "\n",
    "**Date:** May 2, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Work\n",
    "\n",
    "This is an v1 report, prepared in response to the request for information regarding the impact of L1 censorship on the design parameters of the block production phase durations. \n",
    "\n",
    "To answer this question, we have focused on a simplified version of our current modeling efforts. Although we make the trade-off of detail for clarity, the assumptions are based in analysis of an extensive data set of actual blocks from the Ethereum blockchain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Assumptions\n",
    "\n",
    "Any model must make simplifying assumptions. The model in use for the current analysis makes the following assumptions in its logic and execution:\n",
    "\n",
    "* Agents are always *willing* to act. They make no economic considerations with regards to cost or profit. \n",
    "    * As time spent in a particular phase progresses, the probability that an agent will take the indicated action increases towards 1.0.\n",
    "* If the process enters Race Mode, a valid block may still be produced through it.  \n",
    "* There are no censoring validators.\n",
    "* Censoring Builders are pre-set from information of current censorship assumptions. Specifically, we construct a set of \"censoring builders\", and fill it with builders indicated as severely censoring by censorship.pics \n",
    "* Events, such as a builder censoring, are independent (as opposed to them censoring strategically, by then bidding higher on the following slot)\n",
    "\n",
    "This last assumption in particular deserves further exploration, particularly in light of preliminary data analysis below. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Parameters\n",
    "\n",
    "* `N_timesteps`: how many iterations the model should take\n",
    "* `N_samples:` how many Monte Carlo runs \n",
    "\n",
    "\n",
    "The simulation sweeps over all possible combinations of parameter values, as indicated in the following table.\n",
    "\n",
    "| Parameter Name  | Values Swept    |\n",
    "|--------------------------------------|-----------------|\n",
    "| `phase_duration_proposal_min_blocks` | [0, 3] |\n",
    "| `phase_duration_proposal_max_blocks` | [3, 12]|\n",
    "| `phase_duration_reveal_min_blocks`   | [0,3]  |\n",
    "| `phase_duration_reveal_min_blocks`   | [3, 24]|\n",
    "| `phase_duration_reveal_max_blocks`   | [0, 3] |\n",
    "| `phase_duration_commit_bond_min_blocks` | [0,3] |\n",
    "| `phase_duration_commit_bond_max_blocks` | [3,24] |\n",
    "| `phase_duration_rollup_min_blocks`      | [0, 15] |\n",
    "| `phase_duration_rollup_max_blocks`      | [15, 80] |\n",
    "----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Censorship Empirical Data\n",
    "\n",
    "Courtesy of Toni, we use his dataset on builders, validators and mevboost to construct a censorship series.\n",
    "Specifically, we have been provided with an updated dataset going from the Merge until April 25th.\n",
    "To increase relevance, we further dropped all blocks before the Dencun hardfork.\n",
    "\n",
    "With this set, we can construct a timeseries. This timeseries is initially constructed with 'False' for each timestep. By picking a starting block_number from the dataset, we can then set values to 'True' whenever a priorly indicated censoring builder has a slot. This gives as a snapshot of the empirical data, which lets us evaluate quickly whether a simulation timestep is 'censored', disallowing any agent (except for the current L1 builder) to make an L1 transaction. \n",
    "\n",
    "Picking a starting block_number is a bit of an art itself - as an example, we could have picked different start times for every simulation run. This would have let us run over every possible series. However, this would make the results less robust, as we would compare different paramater values over different environments. \n",
    "\n",
    "Instead, we choose to test a starting time for every parameter value. This leaves results more robust. \n",
    "We do this by including starting times as a sweep parameter, building cartesian products with them.\n",
    "To pick starting times, we go with a hybrid approach.\n",
    "On one hand, the goal of this analysis is to start from stringend censorship assumptions - quasi worst case. \n",
    "To emulate that, we are hand-picking some of the start times by choosing time series that include long consecutive runs of slots in a row by the same, main censoring builder: Beaverbuild\n",
    "\n",
    "While handpicking makes up about 20% of our starting times, we Sobol Sample the remaining ones. \n",
    "\n",
    "Future iterations might relax the set of censoring builders, or test incomplete censoring (such as increasing gas price), or introduce strategic censoring. Similarly, we might test different time series (such as before Dencun), sample all series randomly, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KPIs\n",
    "\n",
    "A KPI helps us assess whether simulation trajectories score better or worse on our goals. As trajectories vary in the underlying parameters (such as different phase durations, or block rewards) we can use them to identify parameter combinations that score better on our overall goals. These can be seen in `metrics.py`\n",
    "\n",
    "- `proportion_race_mode`: This measures the proportion of race_mode to total blocks.\n",
    "- `proportion_skipped` : This measures the proportion of blocks that were skipped (no proposals, or no finalized proof).\n",
    "- `average_duration_finalized_blocks`: This measures the average duration of succesfully finalized blocks.\n",
    "- `stddev_duration_finalized_blocks`: This measures the standard deviation of the duration of succesfully finalized blocks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code and Data Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import plotly.io as pio\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from IPython.core.getipython import get_ipython\n",
    "\n",
    "pio.renderers.default = \"png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Data Exploration\n",
    "\n",
    "Restricting the data set to only slots since the Dencun event, it is possible to observe the proportion of blocks for each builder. \n",
    "\n",
    "Key Insights:\n",
    "* The largest builder is `beaverbuild.org`\n",
    "* The full list of censoring builders accounts for 60% of blocks built since Dencun, both over the entire time range and the last 1000 blocks. \n",
    "* The time series of censoring builders shows autocorrelation, which deserves further study and may suggest modifying our assumptions of independence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = '../data/auxiliary/eth_builder_validator_data.parquet.gz'\n",
    "if os.path.isfile(local_path):\n",
    "    data = pd.read_parquet(\n",
    "        local_path).query(f\"slot > 8626718\")\n",
    "else:\n",
    "    data = pd.read_parquet(\n",
    "        's3://aztec-gddt/aux-data/eth_builder_validator_data.parquet.gz').query(f\"slot > 8626718\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DENCUN_SLOT = 8626718\n",
    "data_to_use = data.query(f\"slot > {DENCUN_SLOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENSORING_BUILDERS = ['beaverbuild.org',\n",
    "                      'rsync-builder.xyz', \n",
    "                      'Flashbots', \n",
    "                      'BuildAI (https://buildai.net)', \n",
    "                      'Gambit Labs',\n",
    "                      'boba-builder.com',\n",
    "                      'Builder + www.btcs.com',\n",
    "                      'builder0x69',\n",
    "                      '0x83bee517',\n",
    "                      'BloXroute',\n",
    "                      'I can haz block',\n",
    "                      'EigenPhi',\n",
    "                      'Edennetwork',\n",
    "                      'blockbeelder'\n",
    "                     ]\n",
    "\n",
    "data_to_use.loc[:, 'is_builder_censor'] = data_to_use['builder'].apply(lambda x: int(x in CENSORING_BUILDERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for top builders\n",
    "\n",
    "# Number of top entries you want to display\n",
    "NUM_TOP_ENTRIES = 20\n",
    "\n",
    "# Character length of name, for readability\n",
    "MAX_CHAR_LEN = 30\n",
    "\n",
    "# Calculating the count of each unique value\n",
    "counts = data_to_use['builder'].value_counts()\n",
    "\n",
    "# Selecting the top N entries\n",
    "top_n = counts.nlargest(NUM_TOP_ENTRIES)\n",
    "\n",
    "# Creating a horizontal bar plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "bars = plt.barh(top_n.index, top_n.values)\n",
    "\n",
    "# Color bars based on whether the builder is in the censoring list\n",
    "for bar, builder in zip(bars, top_n.index):\n",
    "    if builder in CENSORING_BUILDERS:\n",
    "        bar.set_color('red')  # Color for censoring builders\n",
    "    else:\n",
    "        bar.set_color('blue')  # Color for non-censoring builders\n",
    "\n",
    "\n",
    "labels = [label[:MAX_CHAR_LEN] + '...'\n",
    "         if len(label) > MAX_CHAR_LEN \n",
    "         else label \n",
    "         for label in top_n.index]\n",
    "\n",
    "plt.xlabel('Number of Blocks')\n",
    "plt.ylabel('Builder Name')\n",
    "plt.yticks(ticks = range(NUM_TOP_ENTRIES), labels=labels)\n",
    "plt.title('Top Builders')\n",
    "plt.gca().invert_yaxis()  # To display the largest at the top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some tests to make sure we use the right data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining total proportion from list\n",
    "data_to_use['is_builder_censor'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_use['is_builder_censor'].head(-1_000).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_use['is_builder_censor'].autocorr(lag = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_use['is_builder_censor'].head(-1_000).autocorr(lag = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Simulation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENT FILE IS A MOCK. NEEDS TO BE CHANGED TO ACTUAL DATA.\n",
    "\n",
    "\n",
    "timestamp = '2024-05-02T134427Z'\n",
    "FILENAME = f\"s3://aztec-gddt/psuu_run_{timestamp}/trajectory_tensor.csv.zip\"\n",
    "sim_df = pd.read_csv(FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHASES = [\"proposal\", \"reveal\", \"commit_bond\", \"rollup\", \"race\"]\n",
    "for phase in PHASES:\n",
    "    min_col = f'phase_duration_{phase}_min_blocks'\n",
    "    max_col = f'phase_duration_{phase}_max_blocks'\n",
    "    sim_df[f'{phase}_is_fixed'] = (sim_df[min_col] == sim_df[max_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop less relevant columns\n",
    "\n",
    "sim_df.drop(columns = ['run', 'subset', 'simulation',\n",
    "       'daily_block_reward',  'proportion_slashed_prover',\n",
    "       'proportion_slashed_sequencer', \n",
    "       'average_duration_finalized_blocks', 'average_duration_nonfinalized_blocks',\n",
    "       'stddev_duration_finalized_blocks', 'stddev_duration_nonfinalized_blocks',\n",
    "       'delta_total_revenue_agents'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information\n",
    "\n",
    "[Mutual Information](https://scikit-learn.org/stable/auto_examples/feature_selection/plot_f_test_vs_mi.html#sphx-glr-auto-examples-feature-selection-plot-f-test-vs-mi-py) can be thought of as a generalization of the correlation coefficient or F-test, tracking the strength of relationships that aren't necessarily linear. \n",
    "\n",
    "In the code below, we\n",
    "* calculate the mutual information between each potential parameter and the KPI.\n",
    "* drop any parameters which have negligible mutual information with KPI.\n",
    "* plot a heatmap of the remaining relationship.\n",
    "\n",
    "This gives insight into which variables are most impactful on the KPIs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "kpis = ['proportion_race_mode', \n",
    "        'proportion_skipped']\n",
    "\n",
    "    \n",
    "features = sim_df.columns.difference(kpis)  # All columns except kpis\n",
    "\n",
    "# Calculate mutual information for each target and store in a DataFrame\n",
    "mi_results = pd.DataFrame(index=features)\n",
    "\n",
    "for kpi in kpis:\n",
    "    mi_scores = mutual_info_regression(sim_df[features], sim_df[kpi])\n",
    "    mi_results[kpi] = mi_scores\n",
    "\n",
    "\n",
    "all_zero_rows = (mi_results < 0.01).all(axis = 1)\n",
    "mi_results = mi_results[~all_zero_rows]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, len(features)))  # Adjust size as needed\n",
    "sns.heatmap(mi_results, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Mutual Information Between Parameters and KPIs')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
