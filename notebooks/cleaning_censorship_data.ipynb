{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Censorship Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "First, make sure the requirements are installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import plotly.io as pio\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from IPython.core.getipython import get_ipython\n",
    "\n",
    "pio.renderers.default = \"png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquiring Data, Combining, and De-duplicating It\n",
    "\n",
    "The code below combines eight total files with ETH L1 data into a single DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARQUET_FILES_TO_USE = [\n",
    "    \"../data/data_000000000000.parquet\",\n",
    "    \"../data/data_000000000001.parquet\",\n",
    "    \"../data/data_000000000002.parquet\",\n",
    "    \"../data/data_000000000003.parquet\",\n",
    "    \"../data/data_000000000004.parquet\",\n",
    "    \"../data/data_000000000005.parquet\",\n",
    "    \"../data/data_000000000006.parquet\",\n",
    "    \"../data/openethdata_eth_data.parquet__1_.gzip\"\n",
    "]\n",
    "\n",
    "data = [pd.read_parquet(file) \n",
    "       for file \n",
    "       in PARQUET_FILES_TO_USE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_data = pd.concat(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cells, we drop duplicate rows, and make sure that the resulting data actually contains no duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_data.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert concatenated_data.duplicated().sum() == 0, \"The concatenated_data frame should have no duplicate rows.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we filter the `concatenated_data` down to only the columns that are relevant to us:\n",
    "* `date`\n",
    "* `slot`\n",
    "* `block_number`\n",
    "* `builder`\n",
    "* `validator`\n",
    "* `builder_pubkey`\n",
    "* `mevboost_value` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_concatenated_data = concatenated_data[['date',\n",
    "                                                'slot',\n",
    "                                                'block_number',\n",
    "                                                'builder',\n",
    "                                                'validator',\n",
    "                                                'builder_pubkey',\n",
    "                                                'mevboost_value']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check to see which columns in `filtered_concatenated_data` have missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                    0\n",
       "slot                    0\n",
       "block_number            8\n",
       "builder            588427\n",
       "validator               0\n",
       "builder_pubkey     588427\n",
       "mevboost_value    5355742\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_concatenated_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the number of entries in `builder` and `builder_pubkey` with missing values is the same. There are more `mevboost_value` entries that are missing. \n",
    "\n",
    "We investigate the conjecture that every row with `builder` and `builder_pubkey` missing also has `mevboost_value` missing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588427"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_concatenated_data[\n",
    "                           (filtered_concatenated_data['builder'].isna())\n",
    "                           & (filtered_concatenated_data['builder_pubkey'].isna())\n",
    "                           ]['mevboost_value'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These correspond to so-called **vanilla blocks**, where the builder and validator are the same. \n",
    "The function `update_builder` replaces the missing `builder` entries with the `validator`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_builder(df):\n",
    "    mask = df['builder'].isnull() & df['builder_pubkey'].isnull() & df['mevboost_value'].isnull()\n",
    "    df.loc[mask, 'builder'] = df.loc[mask, 'validator']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_in_data = update_builder(filtered_concatenated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(filled_in_data) == len(filtered_concatenated_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that this processing is done, we filter out the  `mevboost_value` column so there are no missing values left in the data. We check to see if there are any further missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_in_data = filled_in_data[['date', 'slot', 'block_number', 'builder', 'validator']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date            False\n",
       "slot            False\n",
       "block_number     True\n",
       "builder         False\n",
       "validator       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_in_data.isna().sum() > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `block_number` column still has missing entries. Let's check how many, and see where they are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_in_data['block_number'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>slot</th>\n",
       "      <th>block_number</th>\n",
       "      <th>builder</th>\n",
       "      <th>validator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194300</th>\n",
       "      <td>2023-01-27 06:05:11</td>\n",
       "      <td>5664624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0xb9f106d153a8e96cbfd5cff0ef32e412159b03d5fad1...</td>\n",
       "      <td>0xb9f106d153a8e96cbfd5cff0ef32e412159b03d5fad1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194301</th>\n",
       "      <td>2023-01-27 06:05:23</td>\n",
       "      <td>5664625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0xabbe54e11b0a4ac44794e9ca1bdf2eb0aca86ff5ac60...</td>\n",
       "      <td>0xabbe54e11b0a4ac44794e9ca1bdf2eb0aca86ff5ac60...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194307</th>\n",
       "      <td>2023-01-27 06:06:35</td>\n",
       "      <td>5664631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0xafd0dcfd03b1014f18af4ea70033700ec1c7e823cff3...</td>\n",
       "      <td>0xafd0dcfd03b1014f18af4ea70033700ec1c7e823cff3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194311</th>\n",
       "      <td>2023-01-27 06:07:23</td>\n",
       "      <td>5664635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>missed</td>\n",
       "      <td>missed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194324</th>\n",
       "      <td>2023-01-27 06:09:35</td>\n",
       "      <td>5664646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daniel wang</td>\n",
       "      <td>daniel wang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194327</th>\n",
       "      <td>2023-01-27 06:10:11</td>\n",
       "      <td>5664649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0xb6059f91f339534bddf303a19e7c8578b88ead002aba...</td>\n",
       "      <td>0xb6059f91f339534bddf303a19e7c8578b88ead002aba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194331</th>\n",
       "      <td>2023-01-27 06:10:59</td>\n",
       "      <td>5664653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0xadf148cd30edd5bebf490cd59cdd84e0823389e62cd2...</td>\n",
       "      <td>0xadf148cd30edd5bebf490cd59cdd84e0823389e62cd2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216471</th>\n",
       "      <td>2023-01-27 06:09:35</td>\n",
       "      <td>5664646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x8a0a68a2b4a4b50dada2dc79ecefdff79ac39fee62f4...</td>\n",
       "      <td>0x8a0a68a2b4a4b50dada2dc79ecefdff79ac39fee62f4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date     slot  block_number  \\\n",
       "194300 2023-01-27 06:05:11  5664624           NaN   \n",
       "194301 2023-01-27 06:05:23  5664625           NaN   \n",
       "194307 2023-01-27 06:06:35  5664631           NaN   \n",
       "194311 2023-01-27 06:07:23  5664635           NaN   \n",
       "194324 2023-01-27 06:09:35  5664646           NaN   \n",
       "194327 2023-01-27 06:10:11  5664649           NaN   \n",
       "194331 2023-01-27 06:10:59  5664653           NaN   \n",
       "216471 2023-01-27 06:09:35  5664646           NaN   \n",
       "\n",
       "                                                  builder  \\\n",
       "194300  0xb9f106d153a8e96cbfd5cff0ef32e412159b03d5fad1...   \n",
       "194301  0xabbe54e11b0a4ac44794e9ca1bdf2eb0aca86ff5ac60...   \n",
       "194307  0xafd0dcfd03b1014f18af4ea70033700ec1c7e823cff3...   \n",
       "194311                                             missed   \n",
       "194324                                        daniel wang   \n",
       "194327  0xb6059f91f339534bddf303a19e7c8578b88ead002aba...   \n",
       "194331  0xadf148cd30edd5bebf490cd59cdd84e0823389e62cd2...   \n",
       "216471  0x8a0a68a2b4a4b50dada2dc79ecefdff79ac39fee62f4...   \n",
       "\n",
       "                                                validator  \n",
       "194300  0xb9f106d153a8e96cbfd5cff0ef32e412159b03d5fad1...  \n",
       "194301  0xabbe54e11b0a4ac44794e9ca1bdf2eb0aca86ff5ac60...  \n",
       "194307  0xafd0dcfd03b1014f18af4ea70033700ec1c7e823cff3...  \n",
       "194311                                             missed  \n",
       "194324                                        daniel wang  \n",
       "194327  0xb6059f91f339534bddf303a19e7c8578b88ead002aba...  \n",
       "194331  0xadf148cd30edd5bebf490cd59cdd84e0823389e62cd2...  \n",
       "216471  0x8a0a68a2b4a4b50dada2dc79ecefdff79ac39fee62f4...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_in_data[filled_in_data['block_number'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8505048"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filled_in_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the entries are from early 2023, they are unlikely to be relevant to our data. We drop them all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_18440\\421032421.py:1: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filled_in_data.dropna(axis = 'index',\n",
    "                    inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8505040"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filled_in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert filled_in_data.isna().sum().sum() == 0, \"We are seeing missing values where we would not expect them. \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Data and Checking Information\n",
    "\n",
    "We determine the type of information used in the `date` column, and use it to sort the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(filled_in_data['date'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data = filled_in_data.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sorted_data.isna().sum().sum() == 0, \"This DataFrame should have no missing values. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date            0\n",
       "slot            0\n",
       "block_number    0\n",
       "builder         0\n",
       "validator       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data['slot'].is_monotonic_increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data['block_number'].is_monotonic_increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>slot</th>\n",
       "      <th>block_number</th>\n",
       "      <th>builder</th>\n",
       "      <th>validator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177153</th>\n",
       "      <td>2022-09-15 06:53:23</td>\n",
       "      <td>4700065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missed</td>\n",
       "      <td>missed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338372</th>\n",
       "      <td>2022-09-15 07:02:59</td>\n",
       "      <td>4700113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missed</td>\n",
       "      <td>missed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282694</th>\n",
       "      <td>2022-09-15 07:17:35</td>\n",
       "      <td>4700186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missed</td>\n",
       "      <td>missed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338724</th>\n",
       "      <td>2022-09-15 07:23:59</td>\n",
       "      <td>4700218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missed</td>\n",
       "      <td>missed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181084</th>\n",
       "      <td>2022-09-15 08:13:35</td>\n",
       "      <td>4700466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missed</td>\n",
       "      <td>missed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613794</th>\n",
       "      <td>2024-04-24 03:22:47</td>\n",
       "      <td>8925412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missed</td>\n",
       "      <td>missed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614289</th>\n",
       "      <td>2024-04-24 04:16:47</td>\n",
       "      <td>8925682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missed</td>\n",
       "      <td>missed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614990</th>\n",
       "      <td>2024-04-24 05:31:11</td>\n",
       "      <td>8926054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missed</td>\n",
       "      <td>missed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614996</th>\n",
       "      <td>2024-04-24 05:31:59</td>\n",
       "      <td>8926058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missed</td>\n",
       "      <td>missed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615239</th>\n",
       "      <td>2024-04-24 06:02:11</td>\n",
       "      <td>8926209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missed</td>\n",
       "      <td>missed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30965 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date     slot  block_number builder validator\n",
       "177153  2022-09-15 06:53:23  4700065           0.0  missed    missed\n",
       "3338372 2022-09-15 07:02:59  4700113           0.0  missed    missed\n",
       "282694  2022-09-15 07:17:35  4700186           0.0  missed    missed\n",
       "3338724 2022-09-15 07:23:59  4700218           0.0  missed    missed\n",
       "2181084 2022-09-15 08:13:35  4700466           0.0  missed    missed\n",
       "...                     ...      ...           ...     ...       ...\n",
       "613794  2024-04-24 03:22:47  8925412           0.0  missed    missed\n",
       "614289  2024-04-24 04:16:47  8925682           0.0  missed    missed\n",
       "614990  2024-04-24 05:31:11  8926054           0.0  missed    missed\n",
       "614996  2024-04-24 05:31:59  8926058           0.0  missed    missed\n",
       "615239  2024-04-24 06:02:11  8926209           0.0  missed    missed\n",
       "\n",
       "[30965 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data[sorted_data['block_number'].diff() < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This raises the issue that the data source is using `block_number = 0.0` with `builder = missed` and `validator = missed` as an alternative way of indicating missed blocks, in addition to `None` or `NaN`. \n",
    "\n",
    "We calculate the proportion using this encoding, since they could be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0038304346599192947"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_data[sorted_data['block_number'] == 0])/len(sorted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this data accounts for less than 0.4% of the total data, we can only consider block numbers that are positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data = sorted_data[sorted_data['block_number'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compare the length of the `sorted_data` DataFrame to the number of unique values for `block_number` and `slot`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8472462"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4185174"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_data['block_number'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4195967"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_data['slot'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of `slot`s is slightly larger than the `block_number`, but this is expected behavior. We do a bit more sanity checking here, to see which slots and block numbers are covered by the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15537394.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(sorted_data['block_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19723375.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(sorted_data['block_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4700013"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(sorted_data['slot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8926261"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(sorted_data['slot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Duplicate Rows, Plus Duplicate Entries in Slot and Block Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = sorted_data.sort_values(by=\"date\")\n",
    "dencun_df = sorted_df[(sorted_df[\"block_number\"] > 19426589)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_18440\\453479485.py:1: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dencun_df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dencun_df.duplicated().sum() == 0, \"This DataFrame should have no repeated values. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_18440\\3843717115.py:1: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_18440\\3843717115.py:2: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dencun_df.drop_duplicates(subset=['slot'], inplace=True)\n",
    "dencun_df.drop_duplicates(subset=['block_number'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dencun_df['slot'].duplicated().sum() == 0, \"There are unexpected duplicate slot entries in the data.\"\n",
    "assert dencun_df['block_number'].duplicated().sum() == 0, \"There are unexpected duplicate block number entries in the data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique 'block_number' values: 296786\n",
      "Number of unique 'slots' values: 296786\n",
      "Total number of rows in the DataFrame: 296786\n",
      "Same number of unique values in both columns: True\n",
      "Number of unique values matches total rows: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Checking whether rows, unique blocks and unique slots are equal\n",
    "unique_blocks = dencun_df['block_number'].nunique()\n",
    "unique_slots = dencun_df['slot'].nunique()\n",
    "\n",
    "total_rows = len(dencun_df)\n",
    "\n",
    "same_number_of_uniques = unique_blocks == unique_slots\n",
    "\n",
    "uniques_match_total = unique_blocks == total_rows and unique_slots == total_rows\n",
    "\n",
    "print(f\"Number of unique 'block_number' values: {unique_blocks}\")\n",
    "print(f\"Number of unique 'slots' values: {unique_slots}\")\n",
    "print(f\"Total number of rows in the DataFrame: {total_rows}\")\n",
    "print(\n",
    "    f\"Same number of unique values in both columns: {same_number_of_uniques}\")\n",
    "print(f\"Number of unique values matches total rows: {uniques_match_total}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finishing by Saving the Data\n",
    "\n",
    "At this point, we feel good about calling the data final and saving it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dencun_df.to_csv(\"../data/auxiliary/eth_builder_validator_data.csv.gz\",\n",
    "                          compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dencun_df.to_parquet(\"../data/auxiliary/eth_builder_validator_data.parquet.gz\",\n",
    "                          compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dencun_data_from_csv = pd.read_csv(\"../data/auxiliary/eth_builder_validator_data.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "    assert dencun_data_from_csv.isna().sum().sum() == 0, \"The data should have no missing values.\"\n",
    "    assert dencun_data_from_csv.duplicated().sum() == 0, \"The data should have no missing values.\"\n",
    "    assert dencun_data_from_csv['slot'].duplicated().sum() == 0, \"There are unexpected duplicate slot entries in the data.\"\n",
    "    assert dencun_data_from_csv['block_number'].duplicated().sum() == 0, \"There are unexpected duplicate block number entries in the data.\"\n",
    "    assert len(dencun_data_from_csv) == dencun_data_from_csv['slot'].nunique(), \"Number of slots should be the same as number of entries in data.\"\n",
    "    assert (dencun_data_from_csv['slot'].nunique()) == (dencun_data_from_csv['block_number'].nunique()), \"Number of slots should be the same as number of blocks in data.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dencun_data_from_parquet = pd.read_parquet(\"../data/auxiliary/eth_builder_validator_data.parquet.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "    assert dencun_data_from_parquet.isna().sum().sum() == 0, \"The data should have no missing values.\"\n",
    "    assert dencun_data_from_parquet.duplicated().sum() == 0, \"The data should have no missing values.\"\n",
    "    assert dencun_data_from_parquet['slot'].duplicated().sum() == 0, \"There are unexpected duplicate slot entries in the data.\"\n",
    "    assert dencun_data_from_parquet['block_number'].duplicated().sum() == 0, \"There are unexpected duplicate block number entries in the data.\"\n",
    "    assert len(dencun_data_from_parquet) == dencun_data_from_parquet['slot'].nunique(), \"Number of slots should be the same as number of entries in data.\"\n",
    "    assert (dencun_data_from_parquet['slot'].nunique()) == (dencun_data_from_parquet['block_number'].nunique()), \"Number of slots should be the same as number of blocks in data.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
