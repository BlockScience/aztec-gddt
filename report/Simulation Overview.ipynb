{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70dbbaab",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8e53ec-eaa7-438f-aea9-19534bcee47f",
   "metadata": {},
   "source": [
    "## What do we want to know?\n",
    "\n",
    "* In this experiment group, we are investigating whether the proposed block production workflow falls apart under congestion (\"natural\" or \"strategic\").\n",
    "* There are two different phase designs to be tested:\n",
    "    * Fixed: A phase always ends after a certain amount of time (\"L1 timesteps\").\n",
    "    * Dynamic: A phase can end early if the necessary event has happened.\n",
    "* The block production workflow (and the underlying scenario) should be stable on several margins (\"Goals\")\n",
    "    * G1: L1 Congestion Resilence\n",
    "        * L1 congestion should not introduce too many race modes.\n",
    "    * G2: Predictable & Fast Block Duration\n",
    "        * The Variance and mean duration of blocks should be lower rather than higher.\n",
    "    * G3: Predictable Returns\n",
    "        * The variance in return for actors should be lower rather than higher."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3104f6c1-7e80-4d33-8688-46168d995972",
   "metadata": {},
   "source": [
    "## Experimental Challenge\n",
    "\n",
    "* It is unclear whether certain phase durations are more susceptible to L1 congestion or censorship\n",
    "    * Dynamic Phase durations might provide faster block times (less \"idle\") and might circumvent L1 congestion\n",
    "    * Fixed Phase durations show UX and reward consistency\n",
    "* The duration of these phases needs to be tuned for several constraints:\n",
    "    * Technical Constraint: Is the phase long enough to actually do all the steps? (Assumption for simulation: Technical Feasiblity is given by provided \"safe\" phase durations)\n",
    "    * Economic Constraint: Is the phase long enough to actually do all the steps and bring them on L1, while being profitable?\n",
    "        * This is what we're testing: If L1 gas prices go up (\"shock\"), will block production be severely impacted?\n",
    "        * This depends on economic assumptions: When will Sequencers / Provers find it infeasible to pay more for each L1 action?\n",
    "            * This depends on cost and reward assumptions: If costs are low, and rewards are high, the L1 gas price (and similarly blob gas) increase can more easily be shouldered \n",
    "            * Absent knowing more about cost and reward structures, as well as behavioral components (which \"type\" of agent is more likely to use a 3rd party marketplace? When would they decide to self-prove?) our best approach is to create slots for these assumptions and iteratively \"slot in\" better assumptions, while sweeping over potential parameter ranges. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c099a38-2ac2-4fbf-81b5-e99246ffbc15",
   "metadata": {},
   "source": [
    "## Sweeping\n",
    "\n",
    "Our current Parameter Selection under Uncertainty (PSuU) workflow allows us to sweep over cartesian products of parameter combinations. \n",
    "By running several (currently 5) Monte-Carlo runs on each combination, we are able to create a large number of trajectories. By computing metrics per trajectory, and then comparing them across trajectories as KPIs, the analysis serves to find out which combinations of parameters is beneficial for individual KPIs. Additionally, the KPIs are grouped into utility functions, where each utility function serves one of the three goals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f60296-8ad7-488f-ab83-f36379b375dc",
   "metadata": {},
   "source": [
    "## KPIs\n",
    "A KPI serves to make an assessment over trajectory metrics. There are currently two main distuingishing threshold rules:\n",
    "\n",
    "- BMaT: Below the Median across Trajectories\n",
    "    - E.g. for T1 - Having a lower fraction of blocks that enter race mode is preferable, so we want to tune this to be better below the median. \n",
    "- LMaT: Larger than the Median across Trajectories\n",
    "    - E.g. for payoffs - Having a higher payoff per agent (all else equal) is preferable, so we want to tune this to be better above the median. \n",
    "\n",
    "By assigning a KPI as 0 or 1, according to above threshold rules, we can use them to increase overall utility functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48372fc9",
   "metadata": {},
   "source": [
    "### Utility Functions\n",
    "\n",
    "The utility functions take as input the KPI values and sum them up (currently on equal weights). This allows to iterate over large sets of data quickly, assessing whether a trajectory performed better on a Goal than another. \n",
    "\n",
    "\\begin{align}\n",
    "\\pi_1(C) &= \\sum T_i,  T_i \\in \\mathcal{T}_1\\\\\n",
    "\\pi_2(C) &= \\sum T_i,  T_i \\in \\mathcal{T}_2\\\\\n",
    "\\pi_3(C) &= \\sum T_i,  T_i \\in \\mathcal{T}_3\\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480d36fe-155e-4661-bd33-ec39d150a6c5",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "The calculation for the below metrics can be seen in `metrics.py`:\n",
    "\n",
    "|Identifier|Metric|Applicable Goals|Threshold|\n",
    "|-|-|-|-|\n",
    "|T1|Fraction of Blocks that entered Race Mode|G1|BMaT|\n",
    "|T2|Fraction of Blocks that were slashed due to Provers|G1|BMaT|\n",
    "|T3|Fraction of Blocks that were slashed due to Sequencers|G1|BMaT|\n",
    "|T4|Fraction of Blocks that were skipped|G1|BMaT|\n",
    "|T5|Average of Finalized Blocks Duration|G2|BMaT|\n",
    "|T6|Standard Deviation of Finalized Blocks Duration|G2|BMaT|\n",
    "|T7|Average of Non-Finalized Blocks Duration|G2|BMaT|\n",
    "|T8|Standard Deviation of Non-Finalized Blocks Duration|G2|BMaT|\n",
    "|T9|Standard Deviation of Payoffs to Sequencers|G3|BMaT|\n",
    "|T10|Standard Deviation of Payoffs to Provers|G3|BMaT|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ddf389-0454-4cf7-923e-d878c4ac8adb",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8a6864-e4c3-4b23-8b2c-a969c1094268",
   "metadata": {},
   "source": [
    "### cadCAD Model\n",
    "A cadCAD model consists of policies, state update functions and (partial) state_update_blocks (PSuBs).\n",
    "The model tracks a system state (starting from \"Initial State\") and updates this state based on PSuBs. \n",
    "Each PSuB can include several state update function. \n",
    "Each state update function can call logic from several policies.\n",
    "On each simulation timestep, the model assesses (in order) the PSuBs, and when it hits a condition to trigger, it performs the state update functions, by calling each policy function.\n",
    "The PSuBs can be seen in `structure.py`\n",
    "The state update functions are denoted `s_xxx`, while policy functions are denoted `p_xxx`, and both can be seen in `logic.py` \n",
    "\n",
    "As an example, following is the state update block for evolving from one block to the next - to do so, the update block assesses which phase it is currently in, and uses the respective policy functions to know what to do. It then updates the state variables according to this logic. \n",
    "Note that an L2 block is denoted as `process`. While build-ahead is currently not in spec anymore, it was previously included leading us to plan for several `processes` at the same time. Additionally, having L1 *blocks*, L2 *blocks*, and state update *blocks* gets confusing. \n",
    "```\n",
    "'label': 'Evolve Block Process',\n",
    "'ignore': False,\n",
    "'policies': {\n",
    "    'init_process': p_init_process,\n",
    "    'select_sequencer': p_select_proposal,\n",
    "    'submit_commit_bond': p_commit_bond,\n",
    "    'reveal_block_content': p_reveal_content,\n",
    "    'submit_block_proof': p_submit_proof,\n",
    "    'submit_block_proof_content_race': p_race_mode},\n",
    "'variables': {\n",
    "    'current_process': s_process,\n",
    "    'transactions': s_transactions,\n",
    "    'advance_l1_blocks': s_advance_blocks,\n",
    "    'slashes_to_sequencers': s_slashes_to_sequencer,\n",
    "    'slashes_to_provers': s_slashes_to_prover,\n",
    "    'agents': s_agent_transfer}}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ab94de-e3a7-43ae-a14f-fcc41f18fd24",
   "metadata": {},
   "source": [
    "## Aztec GdDT Model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62142496-68fb-4338-8e86-919e479e90a0",
   "metadata": {},
   "source": [
    "#### Time\n",
    "The model is running on a granular timescale. \n",
    "Specifically, timesteps are measured in L1 blocks (aka 12 seconds).\n",
    "However, if nothing were to happen on a simulation timestep, the simulation skips (and forwards) L1 blocks to increase the time simulated for the same computational complexity. \n",
    "This is particularly present with fixed phases: If a phase is successful before the maximum duration (as the relevant event has happened), instead of going through each timestep, we fast-forward to the end of the phase. This increases L1 blocks simulated, but only increases simulation timesteps by one. This can result in more L1 blocks simulated than simulation timesteps performed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc190c3-a2a1-4b6a-8fc9-027f6038df3f",
   "metadata": {},
   "source": [
    "### Agents and Actions\n",
    "We instantiate several different agents according to classes.\n",
    "\n",
    "**Sequencers and Provers** inherit from the same class. They have an ID, a balance, some stake (or none) and are either a Sequencer, a Prover, or both.\n",
    "\n",
    "**Relays** are used as a separate agent, without balance or stake, to make sure that rewards are tracked correctly.\n",
    "\n",
    "**L1 builder** is a single hard-coded agent, which serves to track race mode rewards. \n",
    "\n",
    "**Burn** is a burn sink, where any tokens that are burnt are sent to for tracking purposes. \n",
    "\n",
    "As Sequencers are the main agent type, they show different behavior throughout the model.\n",
    "Specifically, they decide to make (or not make) certain actions based assessments:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03251d0",
   "metadata": {},
   "source": [
    "#### Willingness to do an action\n",
    "\n",
    "Several factors play into this:\n",
    "* Does an agent want to make an action?\n",
    "* Can an agent make an action? \n",
    "\n",
    "When agents have to make a transaction, such as revealing their block content, they test whether to make it based on a probability. This can be seen in the policy function for phases, such as in `p_commit_bond` in `logic.py`\n",
    "```\n",
    "agent_decides_to_reveal_commit_bond = bernoulli_trial(\n",
    "                        probability=params[\"commit_bond_reveal_probability\"])\n",
    "```\n",
    "For the purpose of this scenario, where we are not testing malicious or accidental actors, the cumulative probability of an agent performing the action during the duration of the phase is currently set to `0.99` and distributed over each timestep. This emulates the fact that it is more likely that an agent performs their action towards the end of a phase.\n",
    "\n",
    "*Limitation:*\n",
    "* Agents do not show different willingness based on type of agent, or other endogenous / exogenous factors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5868cbe5",
   "metadata": {},
   "source": [
    "#### Profitability of completing an action\n",
    "\n",
    "When agents have to make a transaction, such as revealing their block content, they test whether it is profitable for them to continue the action.\n",
    "\n",
    "```\n",
    "gas: Gas = params[\"gas_estimators\"].commitment_bond(state)\n",
    "fee = gas * state[\"gas_fee_l1\"]\n",
    "SAFETY_BUFFER = 2 * fee  # HACK:\n",
    "\n",
    "expected_rewards = params[\"reward_per_block\"]\n",
    "expected_costs: float = params[\"op_costs\"] + fee + SAFETY_BUFFER\n",
    "\n",
    "\n",
    "expected_costs = expected_costs * 1e-9 # Translate to ETH\n",
    "payoff_reveal = expected_rewards - expected_costs\n",
    "```\n",
    "\n",
    "*Limitation:*\n",
    "This simplification currently computes the total rewards for the block, as well as the total costs consisting of the gas of the current transaction to be evaluated, with current gas price, taking a Safety Buffer of currently `x2` for profit margin, and a constant parameter `op_cost` to indicate that agents have their own operational costs to cover as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e1f253",
   "metadata": {},
   "source": [
    "#### Censorship preventing an action\n",
    "\n",
    "While willingness and profitability assumptions cover most decisions, the model also includes a gas threshold and blobgas threshold that agents test again when making decisions. This threshold can be set quite high, to mark gas prices where agents are prohibited from interacting with L1, through censorship or otherwise.\n",
    "This might be in the future reduced to a more accurate profitability functional form, but currently serves to mark absolute censorship thresholds. This can be changed through `params.py`:\n",
    "\n",
    "```\n",
    "gas_threshold_for_tx=70, \n",
    "blob_gas_threshold_for_tx=50,  \n",
    "```\n",
    "\n",
    "*Limitation:* This trigger serves to induce a total shutout from L1. When gas or blob gas prices rise above the current treshold, agents cannot make L1 transactions anymore. When set too low (or sweep values include values that are too low), this can result in no sequencer making proposals, resulting in mass skipped blocks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699a4fb0",
   "metadata": {},
   "source": [
    "### Agent actions happening:\n",
    "\n",
    "When agents have to make a transaction, such as revealing their block content, they test `Willingness`, `Profitability`, and `Censorship`. \n",
    "If all those tests are `True`, they make the transaction, marking the end of the phase. Depending on fixed or dynamical phase durations, we then either fast-forward the simulation or move to the next phase directly.\n",
    "\n",
    "As an example, take this block of code from the policy logic for the commitment bond phase:\n",
    "First, profitability is computed by checking the necessary transaction and current gas price. Similarly, the op_cost bucket, the safety buffer, and the rewards are included. \n",
    "If the first test is successful, willingness is tested. As the current simulation is not geared towards malicious agents or hardware failures, the cumulative probability over all timesteps of the phase is set to 0.99. \n",
    "Additionally, censorship is tested. The gas (and blob gas) thresholds define a complete shutout, so they should be set in accordance with the profitability values. \n",
    "If all tests are successful, the agent makes the commitment_bond transaction and we can transition to the next phase. \n",
    "\n",
    "```\n",
    "gas: Gas = params[\"gas_estimators\"].commitment_bond(state)\n",
    "fee = gas * state[\"gas_fee_l1\"]\n",
    "SAFETY_BUFFER = 2 * fee  # HACK:\n",
    "\n",
    "expected_l2_blocks_per_day = params['l1_blocks_per_day'] / \\\n",
    "    max_phase_duration(params)\n",
    "expected_rewards = params['daily_block_reward'] / \\\n",
    "    expected_l2_blocks_per_day\n",
    "expected_costs: float = params[\"op_costs\"] + \\\n",
    "    fee + SAFETY_BUFFER\n",
    "\n",
    "# Translate to ETH\n",
    "expected_costs = expected_costs * 1e-9\n",
    "\n",
    "payoff_reveal = expected_rewards - expected_costs\n",
    "\n",
    "if payoff_reveal >= 0:\n",
    "\n",
    "    # If duration is not expired, do  a trial to see if bond is commited\n",
    "    agent_decides_to_reveal_commit_bond = bernoulli_trial(\n",
    "        probability=params['final_probability'] /\n",
    "        params['phase_duration_commit_bond_max_blocks']\n",
    "    )\n",
    "    gas_fee_l1_acceptable = (\n",
    "        state[\"gas_fee_l1\"] <= params[\"gas_threshold_for_tx\"]\n",
    "    )\n",
    "    if agent_decides_to_reveal_commit_bond and gas_fee_l1_acceptable:\n",
    "        updated_process = copy(process)\n",
    "        advance_blocks = remaining_time\n",
    "        updated_process.phase = SelectionPhase.pending_reveal\n",
    "        updated_process.duration_in_current_phase = 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe0a9a0",
   "metadata": {},
   "source": [
    "### 3rd party proving marketplace usage: \n",
    "\n",
    "As agents might either be self-proving or using a 3rd party prover marketplace through Sidecar, we currently set a global constant probability that agents use to decide for either possibility when confronted with the choice. \n",
    "\n",
    "\n",
    "*Limitation:*\n",
    "All sequencers currently decide through the same global probability, at the time of decision, whether to self prove or use 3rd party marketplaces.\n",
    "This could be adapted to be specific to agents, instantiated through their class, with probabilities [0, 1] to denote agent types. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8b1aeb",
   "metadata": {},
   "source": [
    "### Rewards and Slashings: \n",
    "\n",
    "There are currently three possible slashings in the model. Each of these has a respective paramater, which is currently a global constant. The Sequencer Slashings can be adapted in `params.py`, while the Prover Slashing can be adapted directly in `logic.py`: \n",
    "\n",
    "* No Commitment Bond is put up: Lead Sequencer gets slashed.\n",
    "* Block Content is not revealed: Lead Sequencer gets slashed.\n",
    "\n",
    "```\n",
    "SLASH_PARAMS = SlashParameters(\n",
    "    failure_to_commit_bond=2,\n",
    "    failure_to_reveal_block=1) #Both in ETH\n",
    "```  \n",
    "\n",
    "\n",
    "* No Rollup Proof is submitted: Prover ID gets slashed (which might be the same as Lead Sequencer, in case of self-proving)\n",
    "```\n",
    "who_to_slash = commit_bond.prover_uuid\n",
    "how_much_to_slash = commit_bond.bond_amount  #full commitment bond is slashed\n",
    "```\n",
    "\n",
    "In all cases, the slashed amount goes to the burn sink. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9c3a06",
   "metadata": {},
   "source": [
    "### L2 Transactions \n",
    "\n",
    "As rewards and costs are assumed to not be constants, but instead depend on the transactions made, the model needs some way to take these into account. Since we are not necessarily interested in the granular dynamics of individual L2 transactions, but instead on their effect on rewards and costs, the model emulates a simplified version.\n",
    "In the state update function `s_transactions_new_proposals`, the following logic can be found:\n",
    "```\n",
    "size = params[\"tx_estimators\"].proposal_average_size(state)\n",
    "public_share = 0.5  # the share of the block as public function calls, which could be used for MEV\n",
    "```\n",
    "Which consumes from `params.py`:\n",
    "```\n",
    "DEFAULT_DETERMINISTIC_TX_ESTIMATOR = UserTransactionEstimators(\n",
    "    transaction_count=lambda _: 1,  # number of transactions\n",
    "    proposal_average_size=lambda _: 100,  # average size in MB \n",
    "    transaction_average_fee_per_size=lambda _: 50.5,  # fee per MB)\n",
    "```\n",
    "\n",
    "This lets the model get more granular blob costs and transaction rewards to agents. \n",
    "\n",
    "*Limitation:*\n",
    "Larger transactions (in MB) only limitedly proxy a higher fee, while similarly setting averages per proposal is a limited way to set transaction fee rewards. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64efd391",
   "metadata": {},
   "source": [
    "### Economic Assets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dff6e7",
   "metadata": {},
   "source": [
    "#### Tokens \n",
    "\n",
    "As currently no empirical data or clear estimate exists on AZT tokens, the model tracks all assets denominated in ETH (denoted \"token\"). While Gas Prices use Gwei, a conversion (1e^9) is used to exchange between them. \n",
    "Currently, there exist rewards, cashbacks and burns. \n",
    "* **Rewards:**\n",
    "    * Block Rewards: We use a daily block reward, which is distributed over the max amount of blocks each day to stay consistent for phase durations\n",
    "    * Transaction Fees: While empirical amounts are unclear, we use a bucket of transactions and fees per transaction to include. \n",
    "* **Cashback:**\n",
    "    * Originally used for fee cashbacks when certain actors make L1 transactions, this is currently disabled. \n",
    "* **Burn:**\n",
    "    * When users are slashed, we send their funds to the burn sink. This could at any point be changed to go to a community treasury or similar.\n",
    "\n",
    "Unless we are testing initial launch conditions, the system starts with some prior ('Initial') state of those, denoted as initial cumulative rewards. These can be set in `params.py`:\n",
    "```\n",
    "INITIAL_CUMM_REWARDS = 200.0 \n",
    "INITIAL_CUMM_CASHBACK = 50.0\n",
    "INITIAL_CUMM_BURN = 50.0\n",
    "```\n",
    "\n",
    "By summing the balance and stake of all actors we can retrieve the current circulating supply. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16512497",
   "metadata": {},
   "source": [
    "#### Gas:\n",
    "Each L1 transaction agents need to complete costs them L1 fees.\n",
    "The assumptions for needed gas can be adapted in `params.py`:\n",
    "\n",
    "```\n",
    "DEFAULT_DETERMINISTIC_GAS_ESTIMATOR = L1GasEstimators(\n",
    "    proposal=lambda _: 100_000,  # type: ignore\n",
    "    commitment_bond=lambda _: 100_000,  # type: ignore\n",
    "    content_reveal=lambda _: 81_000,  # type: ignore\n",
    "    content_reveal_blob=lambda _: 500_000,  # type: ignore\n",
    "    rollup_proof=lambda _: 700_000,  # type: ignore)\n",
    "```\n",
    "\n",
    "The gas price is initialized with a mean value and standard deviation, as well as a timeseries. \n",
    "In the current congestion simulation, we initialize a \"steady state\", which emulates regular L1 behavior. These values can be adapted in `params.py`:\n",
    "```\n",
    "MEAN_STEADY_STATE_L1 = 30\n",
    "DEVIATION_STEADY_STATE_L1 = 2\n",
    "MEAN_STEADY_STATE_BLOB = 15\n",
    "DEVIATION_STEADY_STATE_BLOB = 2\n",
    "```\n",
    "\n",
    "Similarly, two shock scenarios are imposed over the steady state gas price time series:\n",
    "1. **Continuous Shocks:**\n",
    "Emulate a big singular shock, where gas prices are at steady state for the first 25% of the simulation timesteps, then rise sharply, then drop again for the final 25%.\n",
    "Can be seen and adapted in `params.py`:\n",
    "```\n",
    "## Begin: single shock gas estimators defined \n",
    "L1_SHOCK_AMOUNT = 100\n",
    "BLOB_SHOCK_AMOUNT = 100\n",
    "initial_time = floor(0.25 * TIMESTEPS)  # XXX: 25% of timesteps\n",
    "final_time = floor(0.25 * TIMESTEPS)  # XXX: 25% of timesteps\n",
    "```\n",
    "2. **Intermittent Shocks:**\n",
    "Intermittent Shocks emulate reoccuring shocks, modeled through waves. They can be tweaked both on amplitude as well as period of the wave. Can be seen and adapted in `params.py`:\n",
    "\n",
    "\n",
    "```\n",
    "## Begin: intermittent shock gas estimators defined \n",
    "L1_INTER_SHOCK_AMPLITUDE = 100  # Amplitude of wave\n",
    "L1_INTER_SHOCK_PERIOD = 10  # Period of wave\n",
    "num_points = (TIMESTEPS - final_time) - initial_time\n",
    "t = np.arange(initial_time, initial_time + num_points)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa35e13-9adc-47c2-839c-250ef76494b9",
   "metadata": {},
   "source": [
    "### Protocol Parameters\n",
    "\n",
    "The following are protocol parameters that Aztec Labs or later governance can decide to adapt.\n",
    "Sweeping over these lets us test a wide variety of combinations for their effect on KPIs. \n",
    "Note that the lower bound per upper bound parameter decides whether the lower bound of a phase duration is set to 0 (phase can end early), or to the upper bound (phase always goes through entire duration).  \n",
    "\n",
    "| Full Name |  Sweep Variable Name | Sweep Values | Units |\n",
    "| --- | --- | ---| ---|\n",
    "| `ProposalPhaseUpperBound`  | `phase_duration_proposal_max_blocks` | (3, 6, 12) | L1 blocks |\n",
    "| `CommitPhaseUpperBound`       | `phase_duration_commit_bond_max_blocks` | (3, 6, 12) | L1 blocks |\n",
    "| `RevealPhaseUpperBound`   | `phase_duration_reveal_max_blocks` | (3, 12, 24) | L1 blocks |\n",
    "| `ProvingPhaseUpperBound`      | `phase_duration_rollup_max_blocks`  | (15, 40, 80) | L1 blocks |\n",
    "| `RaceModePhaseUpperBound`  | `phase_duration_race_max_blocks`  | (3, 6)  | L1 blocks |\n",
    "| `CommitPhaseLowerBoundPerUpperBound`  | `phase_duration_commit_bond_min_blocks`  | (0, 1)  | LBpUB |\n",
    "| `RevealPhaseLowerBoundPerUpperBound`  | `phase_duration_reveal_min_blocks`  | (0, 1)  | LBpUB |\n",
    "| `ProvingPhaseLowerBoundPerUpperBound`  | `phase_duration_rollup_min_blocks`  | (0, 1)  | LBpUB |\n",
    "| `RaceModePhaseLowerBoundPerUpperBound`  | `phase_duration_race_min_blocks`  | (0, 1)  | LBpUB |\n",
    "| `BlockRewardConstant`  | `reward_per_block`  | ($\\{\\pi_-, \\pi+\\}$)  | GWei |\n",
    "| `CommitBondSize`  | `commit_bond_amount`  | $\\{B_{s,-}, B_{s,+}\\}$  | GWei |\n",
    "| `Reward Share of Provers`  | `rewards_to_provers` | (0.0, 0.1, 0.5) | percentage of rewards |\n",
    "| `Reward Share of Relays`  | `rewards_to_relay` | (0.0, 0.03, 0.1) | percentage of rewards |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72bf30d-49c9-469c-aba3-29bfd1233439",
   "metadata": {},
   "source": [
    "## Computational Complexity\n",
    "\n",
    "A single run (or even a limited amount of trajectories) can easily be done locally. \n",
    "\n",
    "A single trajectory, custom run (setting individual parameters) is useful for testing and sanity checking. A custom_run.nb is available to test different param values, and read statistics from the resulting dataframe.\n",
    "\n",
    "For parameter sweeps, the psuu_run is used. A test_psuu_run.ipynb is available to test the psuu workflow. \n",
    "\n",
    "For large parameter sweeps, with high amounts of trajectories, we use cloud compute to handle both the large datasets for analysis, but also the simulation runs themselves. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e9642a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
